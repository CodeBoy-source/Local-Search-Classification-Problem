\label{index_md_bin_README}%
\Hypertarget{index_md_bin_README}%
\hypertarget{index_autotoc_md1}{}\doxysection{Práctica 1 -\/ Meta\+Heurística}\label{index_autotoc_md1}
\hypertarget{index_autotoc_md2}{}\doxysubsubsection{-\/ Utilize el \char`\"{}cmake CMake\+Lists.\+txt \&\& make\char`\"{} para compilar;}\label{index_autotoc_md2}
\hypertarget{index_autotoc_md3}{}\doxysubsubsection{-\/ Los algoritmos pueden ser ejecutados utilizando los scripts en ./scripts \{\+Ej. run\+All.\+sh\}}\label{index_autotoc_md3}
\hypertarget{index_autotoc_md4}{}\doxysubsubsection{-\/ Los resultados se guardan en ./results;}\label{index_autotoc_md4}
\hypertarget{index_autotoc_md5}{}\doxysubsection{Ejecución individual\+:}\label{index_autotoc_md5}
./bin/\+LSalg ./datos/ionosphere.arff \{seed\} \mbox{[}0-\/1\mbox{]} \{\texorpdfstring{$>$}{>}../results/\+LSalg\+\_\+results.txt\}

./bin/\+Fast\+Greedy ./datos/ionosphere.arff \{clase 1\} \{clase 2\} \{seed\} \mbox{[}0-\/2\mbox{]}\{\texorpdfstring{$>$}{>}../results/\+Greedy\+\_\+results.txt\}

./bin/\+Fast1\+NN ./datos/ionosphere.arff \{clase 1\} \{clase 2\}\{seed\} \mbox{[}0-\/2\mbox{]}\{\texorpdfstring{$>$}{>}../results/1\+NN\+\_\+results.txt\}

Pd\+: \{0=Sin Barajar\}; \{1=Barajando\}; \{2=Equlibrado de Clases\};\hypertarget{index_autotoc_md6}{}\doxysubsection{Descripción breve del Problema}\label{index_autotoc_md6}
La idea es comparar distintos tipos de algoritmos para clasificar datos pertenecientes a una base de datos públicas que nos provee el profesorado. Partiremos primero de la implementación del típico algoritmo de clasficación K-\/\+NN dónde K representa el número de vecinos a mirar y la idea conceptual es buscar los K vecinos más cercanos para realizar una predicción sobre que clase pertenece el objeto a predecir.

Una vez implementado el algoritmo 1NN intentaremos mejorar el porcentaje de aciertos utilizando técnicas de ponderación de características mediante un vector de pesos. El grueso de la práctica está en el cálculo de esos pesos. Utilizaremos un algoritmo \char`\"{}\+Greedy\char`\"{} denominado \char`\"{}\+RELIEF\char`\"{} que utiliza la distancia hacia los amigos (vecinos de la misma clase más cercanos) y enemigos (vecinos de distinta clase más cercano) para incrementar los valores de los pesos para todas las filas pertenecientes al conjunto de entreno. Luego normaliza.

Otra técnica será la búsqueda local utilizando una distribución de varianza 0.\+3 para modificar pesos distintos sin repetición hasta que haya alguna mejora con un total de máximo 15000 evaluaciones o 20$\ast$n siendo n el número de características.

Para comprobar los algoritmos realizaremos un {\itshape cross-\/validation} de 5-\/folds dónde desplazaremos el conjunto de test (correspondiente al 20\%) des final hasta el principio de 20\% en 20\%.

Para la práctica he tenido que definir las funciones en \mbox{\hyperlink{mytools_8h}{mytools.\+h}} y \mbox{\hyperlink{mytools_8cpp}{mytools.\+cpp}}; 